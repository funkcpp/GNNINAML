{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127f15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83c86b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training graphs: 18, Testing graphs: 6\n"
     ]
    }
   ],
   "source": [
    "# 读取训练数据和测试数据\n",
    "dataTrain = []\n",
    "dataTest = []\n",
    "\n",
    "path = 'D:/dataAMLGraph'\n",
    "\n",
    "# 指定日期\n",
    "date = '2022-09-01'\n",
    "\n",
    "# 遍历一天内的小时\n",
    "for hour in range(24):\n",
    "    file_name = f\"subGraph_{date}_{hour:02d}0000.pt\"  # 构造文件名\n",
    "    file_path = f\"{path}/{file_name}\"\n",
    "    \n",
    "    try:\n",
    "        subGraph = torch.load(file_path)\n",
    "        if hour <= 17:   # 0-17 小时作为训练集\n",
    "            dataTrain.append(subGraph)\n",
    "        else:            # 18-23 小时作为测试集\n",
    "            dataTest.append(subGraph)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Training graphs: {len(dataTrain)}, Testing graphs: {len(dataTest)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd57836d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2077023, 3], edge_index=[2, 1380940], edge_attr=[4, 1380940], y=[1380940])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5632af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain[0].edge_attr[3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7a0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GCNWithEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4ff600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNWithEdge(\n",
    "    inFeat=dataTrain[0].x.shape[1],\n",
    "    hiddenFeat=32,\n",
    "    outFeat=16,\n",
    "    embeddingDims=[20, 20],\n",
    "    fchidden=32,\n",
    "    vdim=2,\n",
    "    finalDim=2,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec16280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, Dict, Any, Optional, Union, List\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def calculate_metrics(y_true: torch.Tensor, y_pred: torch.Tensor, average: str = 'binary') -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    计算分类指标\n",
    "    \n",
    "    Args:\n",
    "        y_true: 真实标签\n",
    "        y_pred: 预测标签\n",
    "        average: 多分类时的平均方式 ('binary', 'micro', 'macro', 'weighted')\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含各种指标的字典\n",
    "    \"\"\"\n",
    "    y_true_np = y_true.cpu().numpy()\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        # 精确率\n",
    "        metrics['precision'] = precision_score(y_true_np, y_pred_np, average=average, zero_division=0)\n",
    "        # 召回率\n",
    "        metrics['recall'] = recall_score(y_true_np, y_pred_np, average=average, zero_division=0)\n",
    "        # F1分数\n",
    "        metrics['f1'] = f1_score(y_true_np, y_pred_np, average=average, zero_division=0)\n",
    "        # 准确率\n",
    "        metrics['accuracy'] = (y_pred == y_true).float().mean().item()\n",
    "        \n",
    "        # 混淆矩阵（对于二分类）\n",
    "        if len(torch.unique(y_true)) == 2:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true_np, y_pred_np).ravel()\n",
    "            metrics.update({\n",
    "                'true_negative': tn,\n",
    "                'false_positive': fp,\n",
    "                'false_negative': fn,\n",
    "                'true_positive': tp\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"计算指标时出错: {e}\")\n",
    "        metrics.update({\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'accuracy': 0.0\n",
    "        })\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    使用DataLoader训练模型\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        # 确保标签是long类型\n",
    "        if data.y.dtype != torch.long:\n",
    "            data.y = data.y.long()\n",
    "        \n",
    "        # 前向传播\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(output, data.y)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 统计信息\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 收集预测和真实标签\n",
    "        pred = output.argmax(dim=1)\n",
    "        all_predictions.append(pred)\n",
    "        all_targets.append(data.y)\n",
    "    \n",
    "    # 计算指标\n",
    "    all_pred = torch.cat(all_predictions)\n",
    "    all_target = torch.cat(all_targets)\n",
    "    metrics = calculate_metrics(all_target, all_pred)\n",
    "    metrics['loss'] = total_loss / len(data_loader)\n",
    "    metrics['num_graphs'] = len(data_loader)\n",
    "    metrics['total_samples'] = all_target.size(0)\n",
    "    \n",
    "    return metrics['loss'], metrics\n",
    "\n",
    "\n",
    "def test_model(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    return_predictions: bool = False\n",
    ") -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    使用DataLoader测试模型性能\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # 确保标签是long类型\n",
    "            if data.y.dtype != torch.long:\n",
    "                data.y = data.y.long()\n",
    "            \n",
    "            # 前向传播\n",
    "            output = model(data)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(output, data.y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 收集预测和真实标签\n",
    "            pred = output.argmax(dim=1)\n",
    "            all_predictions.append(pred)\n",
    "            all_targets.append(data.y)\n",
    "            all_outputs.append(output)\n",
    "    \n",
    "    # 计算指标\n",
    "    all_pred = torch.cat(all_predictions)\n",
    "    all_target = torch.cat(all_targets)\n",
    "    metrics = calculate_metrics(all_target, all_pred)\n",
    "    metrics['loss'] = total_loss / len(data_loader)\n",
    "    metrics['num_graphs'] = len(data_loader)\n",
    "    metrics['total_samples'] = all_target.size(0)\n",
    "    \n",
    "    if return_predictions:\n",
    "        metrics['predictions'] = all_pred.cpu()\n",
    "        metrics['targets'] = all_target.cpu()\n",
    "        metrics['outputs'] = torch.cat(all_outputs).cpu()\n",
    "    \n",
    "    return metrics['loss'], metrics\n",
    "\n",
    "\n",
    "def print_detailed_metrics(metrics: Dict[str, Any], phase: str = \"Test\"):\n",
    "    \"\"\"\n",
    "    打印详细的评估指标\n",
    "    \"\"\"\n",
    "    print(f\"\\n{phase} 详细指标:\")\n",
    "    print(f\"损失: {metrics.get('loss', 0):.4f}\")\n",
    "    print(f\"准确率: {metrics.get('accuracy', 0):.4f}\")\n",
    "    print(f\"精确率: {metrics.get('precision', 0):.4f}\")\n",
    "    print(f\"召回率: {metrics.get('recall', 0):.4f}\")\n",
    "    print(f\"F1分数: {metrics.get('f1', 0):.4f}\")\n",
    "    \n",
    "    # 如果是二分类，打印混淆矩阵\n",
    "    if 'true_positive' in metrics:\n",
    "        print(f\"\\n混淆矩阵:\")\n",
    "        print(f\"真阳性(TP): {metrics['true_positive']}\")\n",
    "        print(f\"假阳性(FP): {metrics['false_positive']}\")\n",
    "        print(f\"假阴性(FN): {metrics['false_negative']}\")\n",
    "        print(f\"真阴性(TN): {metrics['true_negative']}\")\n",
    "        \n",
    "        # 计算额外指标\n",
    "        if metrics['true_positive'] + metrics['false_positive'] > 0:\n",
    "            precision = metrics['true_positive'] / (metrics['true_positive'] + metrics['false_positive'])\n",
    "            print(f\"精确率(手动计算): {precision:.4f}\")\n",
    "        \n",
    "        if metrics['true_positive'] + metrics['false_negative'] > 0:\n",
    "            recall = metrics['true_positive'] / (metrics['true_positive'] + metrics['false_negative'])\n",
    "            print(f\"召回率(手动计算): {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70fd97fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "\n",
      "训练集 类别分布:\n",
      "类别 0: 3659316 样本 (99.98%)\n",
      "类别 1: 800 样本 (0.02%)\n",
      "\n",
      "测试集 类别分布:\n",
      "类别 0: 805613 样本 (99.97%)\n",
      "类别 1: 256 样本 (0.03%)\n",
      "类别权重: [0.00043714462663047016, 1.9995629787445068]\n",
      "训练集样本数: 18, 测试集样本数: 6\n",
      "DataLoader 初始化完成\n",
      "开始训练...\n",
      "\n",
      "Epoch 1:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 15260.4419, Acc: 0.7526\n",
      "Test  - Loss: 9654.7983, Acc: 0.5967\n",
      "Test  - Precision: 0.0003, Recall: 0.4219\n",
      "\n",
      "Epoch 2:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 3615.7034, Acc: 0.8374\n",
      "Test  - Loss: 15.8399, Acc: 0.9769\n",
      "Test  - Precision: 0.0011, Recall: 0.0820\n",
      "\n",
      "Epoch 3:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 56.5402, Acc: 0.9796\n",
      "Test  - Loss: 62.0999, Acc: 0.9800\n",
      "Test  - Precision: 0.0013, Recall: 0.0820\n",
      "\n",
      "Epoch 4:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 42.0392, Acc: 0.9820\n",
      "Test  - Loss: 62.1792, Acc: 0.9808\n",
      "Test  - Precision: 0.0012, Recall: 0.0742\n",
      "\n",
      "Epoch 5:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 62.9231, Acc: 0.1274\n",
      "Test  - Loss: 36.3368, Acc: 0.1144\n",
      "Test  - Precision: 0.0003, Recall: 0.9297\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 36.3368\n",
      "准确率: 0.1144\n",
      "精确率: 0.0003\n",
      "召回率: 0.9297\n",
      "F1分数: 0.0007\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 238\n",
      "假阳性(FP): 713623\n",
      "假阴性(FN): 18\n",
      "真阴性(TN): 91990\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 0.9297\n",
      "\n",
      "Epoch 6:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 24.9249, Acc: 0.0211\n",
      "Test  - Loss: 5.0407, Acc: 0.0035\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 7:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 42.1363, Acc: 0.0099\n",
      "Test  - Loss: 10.6551, Acc: 0.0077\n",
      "Test  - Precision: 0.0003, Recall: 0.9766\n",
      "\n",
      "Epoch 8:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 8.3044, Acc: 0.0120\n",
      "Test  - Loss: 4.5989, Acc: 0.0042\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 9:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 18.9144, Acc: 0.0125\n",
      "Test  - Loss: 26.1937, Acc: 0.0100\n",
      "Test  - Precision: 0.0003, Recall: 0.9688\n",
      "\n",
      "Epoch 10:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 39.9323, Acc: 0.0151\n",
      "Test  - Loss: 15.1125, Acc: 0.0085\n",
      "Test  - Precision: 0.0003, Recall: 0.9766\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 15.1125\n",
      "准确率: 0.0085\n",
      "精确率: 0.0003\n",
      "召回率: 0.9766\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 250\n",
      "假阳性(FP): 799038\n",
      "假阴性(FN): 6\n",
      "真阴性(TN): 6575\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 0.9766\n",
      "\n",
      "Epoch 11:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 65.5905, Acc: 0.0280\n",
      "Test  - Loss: 5.5559, Acc: 0.0006\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 12:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 55.1559, Acc: 0.0106\n",
      "Test  - Loss: 65.6261, Acc: 0.1386\n",
      "Test  - Precision: 0.0003, Recall: 0.9180\n",
      "\n",
      "Epoch 13:\n",
      "学习率: 0.001000\n",
      "Train - Loss: 88.9753, Acc: 0.0168\n",
      "Test  - Loss: 22.9700, Acc: 0.0095\n",
      "Test  - Precision: 0.0003, Recall: 0.9688\n",
      "\n",
      "Epoch 14:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 24.7553, Acc: 0.0060\n",
      "Test  - Loss: 12.5989, Acc: 0.0010\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 15:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 40.0308, Acc: 0.0197\n",
      "Test  - Loss: 6.0365, Acc: 0.0007\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 6.0365\n",
      "准确率: 0.0007\n",
      "精确率: 0.0003\n",
      "召回率: 1.0000\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 256\n",
      "假阳性(FP): 805271\n",
      "假阴性(FN): 0\n",
      "真阴性(TN): 342\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 1.0000\n",
      "\n",
      "Epoch 16:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 8.9978, Acc: 0.0039\n",
      "Test  - Loss: 4.7594, Acc: 0.0008\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 17:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 7.7125, Acc: 0.0040\n",
      "Test  - Loss: 7.2084, Acc: 0.0649\n",
      "Test  - Precision: 0.0003, Recall: 0.9609\n",
      "\n",
      "Epoch 18:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 8.7893, Acc: 0.0102\n",
      "Test  - Loss: 4.0915, Acc: 0.0009\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 19:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 8.5879, Acc: 0.0121\n",
      "Test  - Loss: 4.0640, Acc: 0.0009\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 20:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 4.5196, Acc: 0.0012\n",
      "Test  - Loss: 2.5990, Acc: 0.0010\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 2.5990\n",
      "准确率: 0.0010\n",
      "精确率: 0.0003\n",
      "召回率: 1.0000\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 256\n",
      "假阳性(FP): 805031\n",
      "假阴性(FN): 0\n",
      "真阴性(TN): 582\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 1.0000\n",
      "\n",
      "Epoch 21:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 6.2770, Acc: 0.0114\n",
      "Test  - Loss: 7.7695, Acc: 0.0056\n",
      "Test  - Precision: 0.0003, Recall: 0.9922\n",
      "\n",
      "Epoch 22:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 20.3429, Acc: 0.0060\n",
      "Test  - Loss: 4.2491, Acc: 0.0036\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 23:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 17.3253, Acc: 0.0233\n",
      "Test  - Loss: 3.1127, Acc: 0.0026\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 24:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 13.6458, Acc: 0.0195\n",
      "Test  - Loss: 13.5713, Acc: 0.0078\n",
      "Test  - Precision: 0.0003, Recall: 0.9805\n",
      "\n",
      "Epoch 25:\n",
      "学习率: 0.000500\n",
      "Train - Loss: 32.4938, Acc: 0.0172\n",
      "Test  - Loss: 6.9949, Acc: 0.0008\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 6.9949\n",
      "准确率: 0.0008\n",
      "精确率: 0.0003\n",
      "召回率: 1.0000\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 256\n",
      "假阳性(FP): 805230\n",
      "假阴性(FN): 0\n",
      "真阴性(TN): 383\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 1.0000\n",
      "\n",
      "Epoch 26:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 21.4042, Acc: 0.0052\n",
      "Test  - Loss: 5.0806, Acc: 0.0007\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 27:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 13.3486, Acc: 0.0021\n",
      "Test  - Loss: 6.9844, Acc: 0.0008\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 28:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 15.1394, Acc: 0.0109\n",
      "Test  - Loss: 32.3353, Acc: 0.1100\n",
      "Test  - Precision: 0.0003, Recall: 0.9297\n",
      "\n",
      "Epoch 29:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 10.2918, Acc: 0.0136\n",
      "Test  - Loss: 5.0175, Acc: 0.0008\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 30:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 6.4709, Acc: 0.0048\n",
      "Test  - Loss: 3.8643, Acc: 0.0009\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 3.8643\n",
      "准确率: 0.0009\n",
      "精确率: 0.0003\n",
      "召回率: 1.0000\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 256\n",
      "假阳性(FP): 805139\n",
      "假阴性(FN): 0\n",
      "真阴性(TN): 474\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 1.0000\n",
      "\n",
      "Epoch 31:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 2.2568, Acc: 0.0010\n",
      "Test  - Loss: 2.4532, Acc: 0.0016\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 32:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 5.0002, Acc: 0.0100\n",
      "Test  - Loss: 5.1441, Acc: 0.0044\n",
      "Test  - Precision: 0.0003, Recall: 0.9922\n",
      "\n",
      "Epoch 33:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 11.5512, Acc: 0.0025\n",
      "Test  - Loss: 4.9145, Acc: 0.0373\n",
      "Test  - Precision: 0.0003, Recall: 0.9883\n",
      "\n",
      "Epoch 34:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 6.9743, Acc: 0.0158\n",
      "Test  - Loss: 5.2578, Acc: 0.0486\n",
      "Test  - Precision: 0.0003, Recall: 0.9844\n",
      "\n",
      "Epoch 35:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 5.5173, Acc: 0.0172\n",
      "Test  - Loss: 3.6758, Acc: 0.0449\n",
      "Test  - Precision: 0.0003, Recall: 0.9844\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 3.6758\n",
      "准确率: 0.0449\n",
      "精确率: 0.0003\n",
      "召回率: 0.9844\n",
      "F1分数: 0.0007\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 252\n",
      "假阳性(FP): 769654\n",
      "假阴性(FN): 4\n",
      "真阴性(TN): 35959\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 0.9844\n",
      "\n",
      "Epoch 36:\n",
      "学习率: 0.000250\n",
      "Train - Loss: 1.5562, Acc: 0.0128\n",
      "Test  - Loss: 3.5623, Acc: 0.0475\n",
      "Test  - Precision: 0.0003, Recall: 0.9844\n",
      "\n",
      "Epoch 37:\n",
      "学习率: 0.000125\n",
      "Train - Loss: 1.4620, Acc: 0.0111\n",
      "Test  - Loss: 2.8667, Acc: 0.0027\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 38:\n",
      "学习率: 0.000125\n",
      "Train - Loss: 1.4413, Acc: 0.0085\n",
      "Test  - Loss: 3.5616, Acc: 0.0481\n",
      "Test  - Precision: 0.0003, Recall: 0.9844\n",
      "\n",
      "Epoch 39:\n",
      "学习率: 0.000125\n",
      "Train - Loss: 1.8215, Acc: 0.0030\n",
      "Test  - Loss: 2.6240, Acc: 0.0010\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 40:\n",
      "学习率: 0.000125\n",
      "Train - Loss: 2.0058, Acc: 0.0092\n",
      "Test  - Loss: 2.6472, Acc: 0.0295\n",
      "Test  - Precision: 0.0003, Recall: 0.9922\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 2.6472\n",
      "准确率: 0.0295\n",
      "精确率: 0.0003\n",
      "召回率: 0.9922\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 254\n",
      "假阳性(FP): 782094\n",
      "假阴性(FN): 2\n",
      "真阴性(TN): 23519\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 0.9922\n",
      "\n",
      "Epoch 41:\n",
      "学习率: 0.000125\n",
      "Train - Loss: 2.3036, Acc: 0.0025\n",
      "Test  - Loss: 3.9626, Acc: 0.0039\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 42:\n",
      "学习率: 0.000125\n",
      "Train - Loss: 5.1733, Acc: 0.0118\n",
      "Test  - Loss: 6.8397, Acc: 0.0645\n",
      "Test  - Precision: 0.0003, Recall: 0.9609\n",
      "\n",
      "Epoch 43:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 3.0228, Acc: 0.0050\n",
      "Test  - Loss: 2.7886, Acc: 0.0009\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 44:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 2.0037, Acc: 0.0078\n",
      "Test  - Loss: 2.8195, Acc: 0.0009\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 45:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 2.2503, Acc: 0.0009\n",
      "Test  - Loss: 2.6094, Acc: 0.0009\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 2.6094\n",
      "准确率: 0.0009\n",
      "精确率: 0.0003\n",
      "召回率: 1.0000\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 256\n",
      "假阳性(FP): 805117\n",
      "假阴性(FN): 0\n",
      "真阴性(TN): 496\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 1.0000\n",
      "\n",
      "Epoch 46:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 1.2992, Acc: 0.0077\n",
      "Test  - Loss: 2.4489, Acc: 0.0010\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Epoch 47:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 1.5509, Acc: 0.0015\n",
      "Test  - Loss: 2.6941, Acc: 0.0334\n",
      "Test  - Precision: 0.0003, Recall: 0.9883\n",
      "\n",
      "Epoch 48:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 1.4582, Acc: 0.0222\n",
      "Test  - Loss: 2.6821, Acc: 0.0023\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 49:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 2.5746, Acc: 0.0017\n",
      "Test  - Loss: 2.7712, Acc: 0.0026\n",
      "Test  - Precision: 0.0003, Recall: 0.9961\n",
      "\n",
      "Epoch 50:\n",
      "学习率: 0.000063\n",
      "Train - Loss: 1.7554, Acc: 0.0115\n",
      "Test  - Loss: 2.4838, Acc: 0.0009\n",
      "Test  - Precision: 0.0003, Recall: 1.0000\n",
      "\n",
      "Test 详细指标:\n",
      "损失: 2.4838\n",
      "准确率: 0.0009\n",
      "精确率: 0.0003\n",
      "召回率: 1.0000\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 256\n",
      "假阳性(FP): 805111\n",
      "假阴性(FN): 0\n",
      "真阴性(TN): 502\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 1.0000\n",
      "\n",
      "=== 最终评估结果 ===\n",
      "\n",
      "Final Test 详细指标:\n",
      "损失: 2.4838\n",
      "准确率: 0.0009\n",
      "精确率: 0.0003\n",
      "召回率: 1.0000\n",
      "F1分数: 0.0006\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 256\n",
      "假阳性(FP): 805111\n",
      "假阴性(FN): 0\n",
      "真阴性(TN): 502\n",
      "精确率(手动计算): 0.0003\n",
      "召回率(手动计算): 1.0000\n",
      "\n",
      "=== 最佳模型结果 ===\n",
      "最佳测试准确率: 0.9808\n",
      "\n",
      "Best Model 详细指标:\n",
      "损失: 62.1792\n",
      "准确率: 0.9808\n",
      "精确率: 0.0012\n",
      "召回率: 0.0742\n",
      "F1分数: 0.0024\n",
      "\n",
      "混淆矩阵:\n",
      "真阳性(TP): 19\n",
      "假阳性(FP): 15264\n",
      "假阴性(FN): 237\n",
      "真阴性(TN): 790349\n",
      "精确率(手动计算): 0.0012\n",
      "召回率(手动计算): 0.0742\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 1. 包装 dataset\n",
    "class MyGraphDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "# 2. 分析类别分布\n",
    "def analyze_class_distribution(data_list, name=\"Dataset\"):\n",
    "    all_labels = torch.cat([data.y for data in data_list])\n",
    "    class_counts = torch.bincount(all_labels)\n",
    "    total = len(all_labels)\n",
    "    print(f\"\\n{name} 类别分布:\")\n",
    "    for i, count in enumerate(class_counts):\n",
    "        ratio = count / total\n",
    "        print(f\"类别 {i}: {count} 样本 ({ratio:.2%})\")\n",
    "    return class_counts\n",
    "\n",
    "# 3. 计算类别权重\n",
    "def calculate_class_weights(class_counts, device):\n",
    "    weights = 1.0 / class_counts.float()\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "    print(f\"类别权重: {weights.tolist()}\")\n",
    "    return weights.to(device)\n",
    "\n",
    "def create_weighted_sampler_safe(dataset, class_counts):\n",
    "    \"\"\"\n",
    "    每个样本一个权重（适用于图分类，每个data.y是单个标签）\n",
    "    \"\"\"\n",
    "    # 确保每个 data.y 是标量\n",
    "    all_labels = torch.tensor([data.y.item() if data.y.numel() == 1 else int(data.y[0]) for data in dataset])\n",
    "    sample_weights = 1.0 / class_counts[all_labels].float()\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(dataset),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "# 5. 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "\n",
    "    # 确保标签是 long 类型\n",
    "    for data in dataTrain + dataTest:\n",
    "        if data.y.dtype != torch.long:\n",
    "            data.y = data.y.long()\n",
    "\n",
    "    # 包装数据集\n",
    "    train_dataset = MyGraphDataset(dataTrain)\n",
    "    test_dataset = MyGraphDataset(dataTest)\n",
    "\n",
    "    # 类别分布与权重\n",
    "    train_class_counts = analyze_class_distribution(train_dataset.data_list, \"训练集\")\n",
    "    test_class_counts = analyze_class_distribution(test_dataset.data_list, \"测试集\")\n",
    "    class_weights = calculate_class_weights(train_class_counts, device)\n",
    "\n",
    "    # 加权采样器\n",
    "    sampler = create_weighted_sampler_safe(train_dataset, train_class_counts)\n",
    "\n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=1,\n",
    "        sampler=sampler,\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    print(f\"训练集样本数: {len(train_dataset)}, 测试集样本数: {len(test_dataset)}\")\n",
    "    print(\"DataLoader 初始化完成\")\n",
    "\n",
    "    # 初始化模型\n",
    "    model = GCNWithEdge(\n",
    "        inFeat=dataTrain[0].x.shape[1],\n",
    "        hiddenFeat=32,\n",
    "        outFeat=16,\n",
    "        embeddingDims=[20, 20],\n",
    "        fchidden=32,\n",
    "        vdim=2,\n",
    "        finalDim=2,\n",
    "        dropout=0.5\n",
    "    ).to(device)\n",
    "\n",
    "    # 损失函数和优化器\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    # 训练循环\n",
    "    best_test_accuracy = 0\n",
    "    best_metrics = None\n",
    "    print(\"开始训练...\")\n",
    "\n",
    "    for epoch in range(50):\n",
    "        train_loss, train_metrics = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_metrics = test_model(model, test_loader, criterion, device)\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        if test_metrics['accuracy'] > best_test_accuracy:\n",
    "            best_test_accuracy = test_metrics['accuracy']\n",
    "            best_metrics = test_metrics.copy()\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}:\")\n",
    "        print(f\"学习率: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n",
    "        print(f\"Test  - Loss: {test_loss:.4f}, Acc: {test_metrics['accuracy']:.4f}\")\n",
    "        print(f\"Test  - Precision: {test_metrics.get('precision', 0):.4f}, Recall: {test_metrics.get('recall', 0):.4f}\")\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print_detailed_metrics(test_metrics, \"Test\")\n",
    "\n",
    "    # 最终评估\n",
    "    print(\"\\n=== 最终评估结果 ===\")\n",
    "    print_detailed_metrics(test_metrics, \"Final Test\")\n",
    "    print(\"\\n=== 最佳模型结果 ===\")\n",
    "    print(f\"最佳测试准确率: {best_test_accuracy:.4f}\")\n",
    "    if best_metrics:\n",
    "        print_detailed_metrics(best_metrics, \"Best Model\")\n",
    "\n",
    "    # 调整阈值\n",
    "    def find_optimal_threshold(model, test_loader, device, target_precision=0.7):\n",
    "        model.eval()\n",
    "        all_probs = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "                all_probs.append(probs[:, 1])\n",
    "                all_targets.append(data.y)\n",
    "        all_probs = torch.cat(all_probs)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        thresholds = np.linspace(0.3, 0.9, 20)\n",
    "        results = []\n",
    "        for threshold in thresholds:\n",
    "            preds = (all_probs > threshold).long()\n",
    "            precision = precision_score(all_targets.cpu(), preds.cpu(), zero_division=0)\n",
    "            recall = recall_score(all_targets.cpu(), preds.cpu(), zero_division=0)\n",
    "            results.append((threshold, precision, recall))\n",
    "            if precision >= target_precision:\n",
    "                print(f\"阈值 {threshold:.3f}: Precision={precision:.3f}, Recall={recall:.3f}\")\n",
    "        return results\n",
    "\n",
    "    threshold_results = find_optimal_threshold(model, test_loader, device, target_precision=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d5bcf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "类别权重: [1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\pytorchenv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: TrainLoss=0.6990, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 2: TrainLoss=0.4615, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 3: TrainLoss=0.2100, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 4: TrainLoss=0.1425, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 5: TrainLoss=0.1446, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 6: TrainLoss=0.1467, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 7: TrainLoss=0.1425, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 8: TrainLoss=0.1241, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 9: TrainLoss=0.0931, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 10: TrainLoss=0.0975, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 11: TrainLoss=0.1260, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 12: TrainLoss=0.1280, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 13: TrainLoss=0.0943, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 14: TrainLoss=0.0856, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 15: TrainLoss=0.0898, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 16: TrainLoss=0.0687, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 17: TrainLoss=0.0662, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 18: TrainLoss=0.0616, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 19: TrainLoss=0.0596, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 20: TrainLoss=0.0702, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 21: TrainLoss=0.1260, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 22: TrainLoss=0.1794, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 23: TrainLoss=0.0588, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 24: TrainLoss=0.0525, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 25: TrainLoss=0.0576, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 26: TrainLoss=0.0479, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 27: TrainLoss=0.0460, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 28: TrainLoss=0.0568, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 29: TrainLoss=0.0453, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 30: TrainLoss=0.0356, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 31: TrainLoss=0.0375, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 32: TrainLoss=0.0521, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 33: TrainLoss=0.0610, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 34: TrainLoss=0.0301, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 35: TrainLoss=0.0370, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 36: TrainLoss=0.5833, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 37: TrainLoss=0.0368, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 38: TrainLoss=0.0388, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 39: TrainLoss=0.0364, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 40: TrainLoss=0.0493, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 41: TrainLoss=0.0476, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 42: TrainLoss=0.0873, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 43: TrainLoss=0.0548, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 44: TrainLoss=0.0301, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 45: TrainLoss=0.0219, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 46: TrainLoss=0.0230, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 47: TrainLoss=0.0314, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 48: TrainLoss=0.0377, TestF1=0.0000, AUPRC=0.0004, Acc=0.9997\n",
      "Epoch 49: TrainLoss=0.0211, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "Epoch 50: TrainLoss=0.0214, TestF1=0.0000, AUPRC=0.0003, Acc=0.9997\n",
      "\n",
      "=== 最佳模型指标 ===\n",
      "None\n",
      "最佳阈值(精确率≥0.7): 0.500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import f1_score, average_precision_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# ===== Focal Loss =====\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Tensor of shape [num_classes]\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return loss\n",
    "\n",
    "# ===== 计算类别权重 =====\n",
    "def calculate_class_weights(data_list, device):\n",
    "    all_labels = torch.tensor([data.y.item() if data.y.numel() == 1 else int(data.y[0]) for data in data_list])\n",
    "    class_counts = torch.bincount(all_labels)\n",
    "    weights = 1.0 / class_counts.float()\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "    print(f\"类别权重: {weights.tolist()}\")\n",
    "    return weights.to(device), class_counts\n",
    "\n",
    "# ===== 安全加权采样器 =====\n",
    "def create_weighted_sampler_safe(data_list, class_counts):\n",
    "    all_labels = torch.tensor([data.y.item() if data.y.numel() == 1 else int(data.y[0]) for data in data_list])\n",
    "    sample_weights = 1.0 / class_counts[all_labels].float()\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(data_list),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "# ===== 找最优阈值 =====\n",
    "def find_optimal_threshold(model, loader, device, target_precision=0.7):\n",
    "    model.eval()\n",
    "    all_probs, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            probs = torch.softmax(output, dim=1)[:,1]  # 正类概率\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_targets.append(data.y.cpu())\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    thresholds = np.linspace(0.01, 0.5, 50)\n",
    "    best_thresh = 0.5\n",
    "    for th in thresholds:\n",
    "        preds = (all_probs > th).astype(int)\n",
    "        precision = precision_score(all_targets, preds, zero_division=0)\n",
    "        if precision >= target_precision:\n",
    "            best_thresh = th\n",
    "            break\n",
    "    return best_thresh\n",
    "\n",
    "# ===== 主训练脚本 =====\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "\n",
    "    # 确保标签是long类型\n",
    "    for data in dataTrain + dataTest:\n",
    "        if data.y.dtype != torch.long:\n",
    "            data.y = data.y.long()\n",
    "\n",
    "    # 计算类别权重\n",
    "    class_weights, class_counts = calculate_class_weights(dataTrain, device)\n",
    "    sampler = create_weighted_sampler_safe(dataTrain, class_counts)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(dataTrain, batch_size=1, sampler=sampler)\n",
    "    test_loader = DataLoader(dataTest, batch_size=1, shuffle=False)\n",
    "\n",
    "    # 初始化模型\n",
    "    model = GCNWithEdge(\n",
    "        inFeat=dataTrain[0].x.shape[1],\n",
    "        hiddenFeat=32,\n",
    "        outFeat=16,\n",
    "        embeddingDims=[20,20],\n",
    "        fchidden=32,\n",
    "        vdim=2,\n",
    "        finalDim=2,\n",
    "        dropout=0.5\n",
    "    ).to(device)\n",
    "\n",
    "    # 损失函数和优化器\n",
    "    criterion = FocalLoss(gamma=2, alpha=class_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    # 训练循环\n",
    "    best_f1 = 0\n",
    "    best_metrics = None\n",
    "    for epoch in range(50):\n",
    "        # ===== 训练 =====\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # ===== 测试 =====\n",
    "        model.eval()\n",
    "        all_probs, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "                probs = torch.softmax(output, dim=1)[:,1]\n",
    "                all_probs.append(probs.cpu())\n",
    "                all_targets.append(data.y.cpu())\n",
    "        all_probs = torch.cat(all_probs).numpy()\n",
    "        all_targets = torch.cat(all_targets).numpy()\n",
    "        all_preds = (all_probs > 0.5).astype(int)\n",
    "\n",
    "        test_f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "        test_auprc = average_precision_score(all_targets, all_probs)\n",
    "        test_accuracy = (all_preds == all_targets).mean()\n",
    "\n",
    "        # 保存最佳模型（F1为主）\n",
    "        if test_f1 > best_f1:\n",
    "            best_f1 = test_f1\n",
    "            best_metrics = {\n",
    "                'f1': test_f1,\n",
    "                'auprc': test_auprc,\n",
    "                'accuracy': test_accuracy\n",
    "            }\n",
    "            torch.save(model.state_dict(), 'best_model_f1.pth')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: TrainLoss={train_loss:.4f}, TestF1={test_f1:.4f}, AUPRC={test_auprc:.4f}, Acc={test_accuracy:.4f}\")\n",
    "\n",
    "    # ===== 最终输出 =====\n",
    "    print(\"\\n=== 最佳模型指标 ===\")\n",
    "    print(best_metrics)\n",
    "\n",
    "    # ===== 自动寻找最佳阈值 =====\n",
    "    best_threshold = find_optimal_threshold(model, test_loader, device, target_precision=0.7)\n",
    "    print(f\"最佳阈值(精确率≥0.7): {best_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44591ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立baseline模型\n",
    "# 将卷积层和边信息结合，在这里我们先不考虑时间顺序，只是搭建一个baseline模型\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch import nn\n",
    "\n",
    "'''\n",
    "infeat:GCN层输入维数\n",
    "hiddenFeat:GCN层隐含维数\n",
    "outFeat:GCN层输出维数\n",
    "embeddingDims:属性数据嵌入维数\n",
    "fchidden:属性数据输出隐藏层维数\n",
    "vdim:数值数据维数\n",
    "finalDim:最后的输出层维数\n",
    "'''\n",
    "class GCNWithEdge(nn.Module):\n",
    "    def __init__(self,\n",
    "                 inFeat,\n",
    "                 hiddenFeat,\n",
    "                 outFeat,\n",
    "                 embeddingDims = [20,20],\n",
    "                 fchidden = 32,\n",
    "                 vdim = 2,\n",
    "                 finalDim = 2,\n",
    "                 dropout = 0.5):\n",
    "        super(GCNWithEdge, self).__init__()\n",
    "        \n",
    "        # 由于数据集较大，故我们对于GCN要求的层数不能过多，在这里做为baseline我们只要求有两层gcn链接\n",
    "        self.conv1 = GCNConv(inFeat, hiddenFeat)\n",
    "        self.conv2 = GCNConv(hiddenFeat, outFeat)\n",
    "\n",
    "        # 构建处理属性数据层\n",
    "        self.embeddingList = nn.ModuleList()\n",
    "        for dim in embeddingDims:\n",
    "            self.embeddingList.append(torch.nn.Embedding(dim, fchidden))\n",
    "        \n",
    "        self.finalLayer = nn.Sequential(\n",
    "            nn.Linear(outFeat + len(embeddingDims)*fchidden + vdim, finalDim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),    \n",
    "            nn.Linear(finalDim, 2)  # 假设二分类问题\n",
    "        )\n",
    "    \n",
    "    def forward(self, \n",
    "                data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        # gcn得到节点特征\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index) # x : [num_node,outFeat]\n",
    "\n",
    "        # 将节点数据转换为边数据\n",
    "        edgeIndex = data.edge_index\n",
    "        start,end = edgeIndex\n",
    "        node2Edge = x[start] - x[end]  #node2Edge : [num_edge,outFeat]\n",
    "\n",
    "        # 提取属性数据\n",
    "        edgeAttr = edge_attr.T # edgeAttr : [num_edge, num_attr]\n",
    "        vlData = edgeAttr[:, :2].float()\n",
    "\n",
    "        for i in range(len(self.embeddingList)):\n",
    "            emb = self.embeddingList[i]\n",
    "            vlData = torch.cat([vlData, emb(edgeAttr[:, i+2].long())], dim=1)\n",
    "        \n",
    "        total = torch.cat([node2Edge, vlData], dim=1)\n",
    "\n",
    "        out = self.finalLayer(total)\n",
    "\n",
    "        return F.log_softmax(out, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f70838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNWithEdge(\n",
    "    inFeat=dataTrain[0].x.shape[1],\n",
    "    hiddenFeat=32,\n",
    "    outFeat=16,\n",
    "    embeddingDims=[20, 20],\n",
    "    fchidden=32,\n",
    "    vdim=2,\n",
    "    finalDim=2,\n",
    "    dropout=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ce95330",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(dataTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0388616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.3382e-01, -8.8276e-01],\n",
      "        [-1.2078e+02,  0.0000e+00],\n",
      "        [-2.9309e+01,  0.0000e+00],\n",
      "        ...,\n",
      "        [-2.3299e+03,  0.0000e+00],\n",
      "        [-1.0671e+00, -4.2162e-01],\n",
      "        [-5.3382e-01, -8.8276e-01]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
